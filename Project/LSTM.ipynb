{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "nmuHc2SdAUfE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "aAk_WZrhAXnu",
    "outputId": "18051a94-2e02-4a95-ea20-f28fb98f2fe7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87544</th>\n",
       "      <td>0.621951</td>\n",
       "      <td>0.521341</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.457317</td>\n",
       "      <td>0.417683</td>\n",
       "      <td>0.362805</td>\n",
       "      <td>0.295732</td>\n",
       "      <td>0.253049</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87545</th>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.526515</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87546</th>\n",
       "      <td>0.757235</td>\n",
       "      <td>0.663987</td>\n",
       "      <td>0.561093</td>\n",
       "      <td>0.453376</td>\n",
       "      <td>0.324759</td>\n",
       "      <td>0.218650</td>\n",
       "      <td>0.144695</td>\n",
       "      <td>0.106109</td>\n",
       "      <td>0.085209</td>\n",
       "      <td>0.120579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87547</th>\n",
       "      <td>0.717325</td>\n",
       "      <td>0.627660</td>\n",
       "      <td>0.534954</td>\n",
       "      <td>0.427052</td>\n",
       "      <td>0.322188</td>\n",
       "      <td>0.215805</td>\n",
       "      <td>0.136778</td>\n",
       "      <td>0.068389</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87548</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.440559</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.374126</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.279720</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87549 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1      0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2      1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3      0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4      0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "87544  0.621951  0.521341  0.463415  0.457317  0.417683  0.362805  0.295732   \n",
       "87545  0.799242  0.515152  0.545455  0.553030  0.526515  0.503788  0.424242   \n",
       "87546  0.757235  0.663987  0.561093  0.453376  0.324759  0.218650  0.144695   \n",
       "87547  0.717325  0.627660  0.534954  0.427052  0.322188  0.215805  0.136778   \n",
       "87548  1.000000  0.405594  0.440559  0.405594  0.405594  0.384615  0.374126   \n",
       "\n",
       "            7         8         9    ...  178  179  180  181  182  183  184  \\\n",
       "0      0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "87544  0.253049  0.146341  0.048780  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87545  0.344697  0.196970  0.034091  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87546  0.106109  0.085209  0.120579  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87547  0.068389  0.042553  0.039514  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87548  0.318182  0.279720  0.167832  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       185  186  187  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "87544  0.0  0.0  1.0  \n",
       "87545  0.0  0.0  1.0  \n",
       "87546  0.0  0.0  1.0  \n",
       "87547  0.0  0.0  1.0  \n",
       "87548  0.0  0.0  1.0  \n",
       "\n",
       "[87549 rows x 188 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing 5 classes with 2\n",
    "mitbih_train = pd.read_csv(\"mitbih_train.csv\", header=None)\n",
    "mitbih_train[187].replace({2: 1, 3: 1, 4: 1}, inplace=True)\n",
    "mitbih_train.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "rRT7DWc9INbF",
    "outputId": "da40ea13-d01e-4bef-c487-e854e4b79f7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758264</td>\n",
       "      <td>0.111570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.078512</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.049587</td>\n",
       "      <td>0.047521</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908425</td>\n",
       "      <td>0.783883</td>\n",
       "      <td>0.531136</td>\n",
       "      <td>0.362637</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.344322</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.730088</td>\n",
       "      <td>0.212389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.101770</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.132743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910417</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.472917</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.054167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.399329</td>\n",
       "      <td>0.238255</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.040268</td>\n",
       "      <td>0.080537</td>\n",
       "      <td>0.070470</td>\n",
       "      <td>0.090604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21882</th>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.613383</td>\n",
       "      <td>0.650558</td>\n",
       "      <td>0.646840</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>0.579926</td>\n",
       "      <td>0.509294</td>\n",
       "      <td>0.371747</td>\n",
       "      <td>0.223048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21883</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.480687</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.592275</td>\n",
       "      <td>0.643777</td>\n",
       "      <td>0.660944</td>\n",
       "      <td>0.648069</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21884</th>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.542253</td>\n",
       "      <td>0.542253</td>\n",
       "      <td>0.552817</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.524648</td>\n",
       "      <td>0.528169</td>\n",
       "      <td>0.461268</td>\n",
       "      <td>0.320423</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930337</td>\n",
       "      <td>0.858427</td>\n",
       "      <td>0.774157</td>\n",
       "      <td>0.658427</td>\n",
       "      <td>0.524719</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.296629</td>\n",
       "      <td>0.203371</td>\n",
       "      <td>0.158427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21886</th>\n",
       "      <td>0.801829</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.518293</td>\n",
       "      <td>0.472561</td>\n",
       "      <td>0.454268</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.368902</td>\n",
       "      <td>0.310976</td>\n",
       "      <td>0.253049</td>\n",
       "      <td>0.164634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21887 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      1.000000  0.758264  0.111570  0.000000  0.080579  0.078512  0.066116   \n",
       "1      0.908425  0.783883  0.531136  0.362637  0.366300  0.344322  0.333333   \n",
       "2      0.730088  0.212389  0.000000  0.119469  0.101770  0.101770  0.110619   \n",
       "3      1.000000  0.910417  0.681250  0.472917  0.229167  0.068750  0.000000   \n",
       "4      0.570470  0.399329  0.238255  0.147651  0.000000  0.003356  0.040268   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21882  0.862454  0.613383  0.650558  0.646840  0.631970  0.579926  0.509294   \n",
       "21883  1.000000  0.463519  0.480687  0.506438  0.575107  0.592275  0.643777   \n",
       "21884  0.992958  0.542253  0.542253  0.552817  0.549296  0.524648  0.528169   \n",
       "21885  1.000000  0.930337  0.858427  0.774157  0.658427  0.524719  0.400000   \n",
       "21886  0.801829  0.524390  0.518293  0.472561  0.454268  0.408537  0.368902   \n",
       "\n",
       "            7         8         9    ...  178  179  180  181  182  183  184  \\\n",
       "0      0.049587  0.047521  0.035124  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.307692  0.296703  0.300366  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.123894  0.115044  0.132743  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.004167  0.014583  0.054167  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.080537  0.070470  0.090604  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "21882  0.371747  0.223048  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21883  0.660944  0.648069  0.519313  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21884  0.461268  0.320423  0.207746  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21885  0.296629  0.203371  0.158427  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "21886  0.310976  0.253049  0.164634  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       185  186  187  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "21882  0.0  0.0  1.0  \n",
       "21883  0.0  0.0  1.0  \n",
       "21884  0.0  0.0  1.0  \n",
       "21885  0.0  0.0  1.0  \n",
       "21886  0.0  0.0  1.0  \n",
       "\n",
       "[21887 rows x 188 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mitbih_test = pd.read_csv(\"mitbih_test.csv\", header=None)\n",
    "mitbih_test[187].replace({2: 1, 3: 1, 4: 1}, inplace=True)\n",
    "mitbih_test.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932233</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.886186</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.908775</td>\n",
       "      <td>0.933970</td>\n",
       "      <td>0.801043</td>\n",
       "      <td>0.749783</td>\n",
       "      <td>0.687229</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606941</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.223567</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>0.253430</td>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.153349</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.791859</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.667435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.899261</td>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.328096</td>\n",
       "      <td>0.367837</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935618</td>\n",
       "      <td>0.801661</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>0.480789</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.319834</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.932233  0.869679  0.886186  0.929626  0.908775  0.933970  0.801043   \n",
       "1  1.000000  0.606941  0.384181  0.254237  0.223567  0.276836  0.253430   \n",
       "2  1.000000  0.951613  0.923963  0.853303  0.791859  0.734255  0.672043   \n",
       "3  0.977819  0.899261  0.230129  0.032348  0.142329  0.223660  0.328096   \n",
       "4  0.935618  0.801661  0.805815  1.000000  0.722741  0.480789  0.454829   \n",
       "\n",
       "        7         8         9    ...  178  179  180  181  182  183  184  185  \\\n",
       "0  0.749783  0.687229  0.635100  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.184826  0.153349  0.121872  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.685100  0.670507  0.667435  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.367837  0.381701  0.389094  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.319834  0.266874  0.308411  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   186  187  \n",
       "0  0.0  1.0  \n",
       "1  0.0  1.0  \n",
       "2  0.0  1.0  \n",
       "3  0.0  1.0  \n",
       "4  0.0  1.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phys_data = pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "phys_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drzULxQgTrPk",
    "outputId": "43f9232e-af73-48fc-dea4-eb9e505831a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    72471\n",
      "1.0    15083\n",
      "Name: 187, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2 classes\n",
    "np.unique(mitbih_train.iloc[:,-1])\n",
    "c=mitbih_train.iloc[:,-1].value_counts()\n",
    "print(c.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging and splitting train and test data from different CSV\n",
    "#mitbih_train=mitbih_train.append(phys_data)\n",
    "Xtrain,Xval,Ytrain,Yval=train_test_split(mitbih_train.iloc[:,:-1], mitbih_train.iloc[:,-1],test_size=0.2, random_state=1)\n",
    "Xtrain = np.reshape(np.array(Xtrain),(Xtrain.shape[0], 1, Xtrain.shape[1]))\n",
    "Xval=np.reshape(np.array(Xval),(Xval.shape[0], 1, Xval.shape[1]))\n",
    "Xtest=mitbih_test.iloc[:,:-1]\n",
    "Xtest = np.reshape(np.array(Xtest), (Xtest.shape[0], 1, Xtest.shape[1]))\n",
    "Ytrain=tf.keras.utils.to_categorical(Ytrain,num_classes=2)\n",
    "Ytest=mitbih_test.iloc[:,-1]\n",
    "Ytest=tf.keras.utils.to_categorical(Ytest,num_classes=2)\n",
    "Yval=tf.keras.utils.to_categorical(Yval,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70043 samples, validate on 17511 samples\n",
      "Epoch 1/100\n",
      "70043/70043 [==============================] - 6s 79us/step - loss: 0.6080 - categorical_accuracy: 0.8076 - val_loss: 0.2783 - val_categorical_accuracy: 0.9054\n",
      "Epoch 2/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.2467 - categorical_accuracy: 0.9137 - val_loss: 0.2004 - val_categorical_accuracy: 0.9376\n",
      "Epoch 3/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.2027 - categorical_accuracy: 0.9303 - val_loss: 0.1804 - val_categorical_accuracy: 0.9396\n",
      "Epoch 4/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1772 - categorical_accuracy: 0.9391 - val_loss: 0.1583 - val_categorical_accuracy: 0.9495\n",
      "Epoch 5/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1740 - categorical_accuracy: 0.9403 - val_loss: 0.1506 - val_categorical_accuracy: 0.9513\n",
      "Epoch 6/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1666 - categorical_accuracy: 0.9438 - val_loss: 0.1417 - val_categorical_accuracy: 0.9548\n",
      "Epoch 7/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1610 - categorical_accuracy: 0.9457 - val_loss: 0.1414 - val_categorical_accuracy: 0.9540\n",
      "Epoch 8/100\n",
      "70043/70043 [==============================] - 5s 77us/step - loss: 0.1554 - categorical_accuracy: 0.9476 - val_loss: 0.1346 - val_categorical_accuracy: 0.9576\n",
      "Epoch 9/100\n",
      "70043/70043 [==============================] - 5s 71us/step - loss: 0.1531 - categorical_accuracy: 0.9478 - val_loss: 0.1316 - val_categorical_accuracy: 0.9575\n",
      "Epoch 10/100\n",
      "70043/70043 [==============================] - 5s 70us/step - loss: 0.1423 - categorical_accuracy: 0.9522 - val_loss: 0.1307 - val_categorical_accuracy: 0.9553\n",
      "Epoch 11/100\n",
      "70043/70043 [==============================] - 5s 78us/step - loss: 0.1409 - categorical_accuracy: 0.9531 - val_loss: 0.1276 - val_categorical_accuracy: 0.9567\n",
      "Epoch 12/100\n",
      "70043/70043 [==============================] - 4s 64us/step - loss: 0.1418 - categorical_accuracy: 0.9521 - val_loss: 0.1339 - val_categorical_accuracy: 0.9579\n",
      "Epoch 13/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1393 - categorical_accuracy: 0.9530 - val_loss: 0.1426 - val_categorical_accuracy: 0.9527\n",
      "Epoch 14/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1421 - categorical_accuracy: 0.9522 - val_loss: 0.1328 - val_categorical_accuracy: 0.9583\n",
      "Epoch 15/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1367 - categorical_accuracy: 0.9541 - val_loss: 0.1353 - val_categorical_accuracy: 0.9581\n",
      "Epoch 16/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1361 - categorical_accuracy: 0.9540 - val_loss: 0.1149 - val_categorical_accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1315 - categorical_accuracy: 0.9560 - val_loss: 0.1191 - val_categorical_accuracy: 0.9612\n",
      "Epoch 18/100\n",
      "70043/70043 [==============================] - 5s 70us/step - loss: 0.1319 - categorical_accuracy: 0.9560 - val_loss: 0.1199 - val_categorical_accuracy: 0.9623\n",
      "Epoch 19/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1344 - categorical_accuracy: 0.9548 - val_loss: 0.1348 - val_categorical_accuracy: 0.9576\n",
      "Epoch 20/100\n",
      "70043/70043 [==============================] - 5s 69us/step - loss: 0.1388 - categorical_accuracy: 0.9530 - val_loss: 0.1187 - val_categorical_accuracy: 0.9625\n",
      "Epoch 21/100\n",
      "70043/70043 [==============================] - 5s 74us/step - loss: 0.1268 - categorical_accuracy: 0.9578 - val_loss: 0.1244 - val_categorical_accuracy: 0.9602\n",
      "Epoch 22/100\n",
      "70043/70043 [==============================] - 5s 70us/step - loss: 0.1247 - categorical_accuracy: 0.9588 - val_loss: 0.1129 - val_categorical_accuracy: 0.9628\n",
      "Epoch 23/100\n",
      "70043/70043 [==============================] - 4s 63us/step - loss: 0.1263 - categorical_accuracy: 0.9581 - val_loss: 0.1138 - val_categorical_accuracy: 0.9629\n",
      "Epoch 24/100\n",
      "70043/70043 [==============================] - 5s 78us/step - loss: 0.1267 - categorical_accuracy: 0.9576 - val_loss: 0.1325 - val_categorical_accuracy: 0.9611\n",
      "Epoch 25/100\n",
      "70043/70043 [==============================] - 6s 84us/step - loss: 0.1370 - categorical_accuracy: 0.9553 - val_loss: 0.1281 - val_categorical_accuracy: 0.9605\n",
      "Epoch 26/100\n",
      "70043/70043 [==============================] - 6s 83us/step - loss: 0.1366 - categorical_accuracy: 0.9561 - val_loss: 0.1286 - val_categorical_accuracy: 0.9633\n",
      "Epoch 27/100\n",
      "70043/70043 [==============================] - 6s 89us/step - loss: 0.1333 - categorical_accuracy: 0.9578 - val_loss: 0.1287 - val_categorical_accuracy: 0.9608\n",
      "Epoch 28/100\n",
      "70043/70043 [==============================] - 5s 76us/step - loss: 0.1381 - categorical_accuracy: 0.9548 - val_loss: 0.1215 - val_categorical_accuracy: 0.9629\n",
      "Epoch 29/100\n",
      "70043/70043 [==============================] - 5s 78us/step - loss: 0.1375 - categorical_accuracy: 0.9548 - val_loss: 0.1221 - val_categorical_accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "70043/70043 [==============================] - 6s 85us/step - loss: 0.1326 - categorical_accuracy: 0.9564 - val_loss: 0.1096 - val_categorical_accuracy: 0.9652\n",
      "Epoch 31/100\n",
      "70043/70043 [==============================] - 4s 64us/step - loss: 0.1239 - categorical_accuracy: 0.9596 - val_loss: 0.1343 - val_categorical_accuracy: 0.9592\n",
      "Epoch 32/100\n",
      "70043/70043 [==============================] - 5s 66us/step - loss: 0.1377 - categorical_accuracy: 0.9544 - val_loss: 0.1082 - val_categorical_accuracy: 0.9665\n",
      "Epoch 33/100\n",
      "70043/70043 [==============================] - 5s 77us/step - loss: 0.1270 - categorical_accuracy: 0.9580 - val_loss: 0.1116 - val_categorical_accuracy: 0.9652\n",
      "Epoch 34/100\n",
      "70043/70043 [==============================] - 6s 83us/step - loss: 0.1289 - categorical_accuracy: 0.9573 - val_loss: 0.1197 - val_categorical_accuracy: 0.9638\n",
      "Epoch 35/100\n",
      "70043/70043 [==============================] - 5s 72us/step - loss: 0.1286 - categorical_accuracy: 0.9582 - val_loss: 0.1138 - val_categorical_accuracy: 0.9651\n",
      "Epoch 36/100\n",
      "70043/70043 [==============================] - 5s 66us/step - loss: 0.1283 - categorical_accuracy: 0.9573 - val_loss: 0.1130 - val_categorical_accuracy: 0.9649\n",
      "Epoch 37/100\n",
      "70043/70043 [==============================] - 4s 59us/step - loss: 0.1359 - categorical_accuracy: 0.9547 - val_loss: 0.1119 - val_categorical_accuracy: 0.9641\n",
      "Epoch 38/100\n",
      "70043/70043 [==============================] - 4s 64us/step - loss: 0.1264 - categorical_accuracy: 0.9589 - val_loss: 0.1135 - val_categorical_accuracy: 0.9641\n",
      "Epoch 39/100\n",
      "70043/70043 [==============================] - 5s 67us/step - loss: 0.1224 - categorical_accuracy: 0.9605 - val_loss: 0.1097 - val_categorical_accuracy: 0.9660\n",
      "Epoch 40/100\n",
      "70043/70043 [==============================] - 5s 66us/step - loss: 0.1287 - categorical_accuracy: 0.9576 - val_loss: 0.1152 - val_categorical_accuracy: 0.9640\n",
      "Epoch 41/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1288 - categorical_accuracy: 0.9575 - val_loss: 0.1120 - val_categorical_accuracy: 0.9652\n",
      "Epoch 42/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1255 - categorical_accuracy: 0.9594 - val_loss: 0.1149 - val_categorical_accuracy: 0.9653\n",
      "Epoch 43/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1328 - categorical_accuracy: 0.9555 - val_loss: 0.1197 - val_categorical_accuracy: 0.9637\n",
      "Epoch 44/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1338 - categorical_accuracy: 0.9559 - val_loss: 0.1137 - val_categorical_accuracy: 0.9655\n",
      "Epoch 45/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1320 - categorical_accuracy: 0.9554 - val_loss: 0.1083 - val_categorical_accuracy: 0.9679\n",
      "Epoch 46/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1206 - categorical_accuracy: 0.9610 - val_loss: 0.1145 - val_categorical_accuracy: 0.9672\n",
      "Epoch 47/100\n",
      "70043/70043 [==============================] - 4s 64us/step - loss: 0.1213 - categorical_accuracy: 0.9600 - val_loss: 0.1264 - val_categorical_accuracy: 0.9627\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1219 - categorical_accuracy: 0.9595 - val_loss: 0.1075 - val_categorical_accuracy: 0.9673\n",
      "Epoch 49/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1258 - categorical_accuracy: 0.9582 - val_loss: 0.1059 - val_categorical_accuracy: 0.9668\n",
      "Epoch 50/100\n",
      "70043/70043 [==============================] - 4s 56us/step - loss: 0.1264 - categorical_accuracy: 0.9584 - val_loss: 0.1175 - val_categorical_accuracy: 0.9649\n",
      "Epoch 51/100\n",
      "70043/70043 [==============================] - 4s 63us/step - loss: 0.1252 - categorical_accuracy: 0.9575 - val_loss: 0.1292 - val_categorical_accuracy: 0.9616\n",
      "Epoch 52/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1221 - categorical_accuracy: 0.9594 - val_loss: 0.1143 - val_categorical_accuracy: 0.9656\n",
      "Epoch 53/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1194 - categorical_accuracy: 0.9613 - val_loss: 0.1062 - val_categorical_accuracy: 0.9682\n",
      "Epoch 54/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1192 - categorical_accuracy: 0.9606 - val_loss: 0.1191 - val_categorical_accuracy: 0.9615\n",
      "Epoch 55/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1315 - categorical_accuracy: 0.9541 - val_loss: 0.1186 - val_categorical_accuracy: 0.9627\n",
      "Epoch 56/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1279 - categorical_accuracy: 0.9568 - val_loss: 0.1126 - val_categorical_accuracy: 0.9653\n",
      "Epoch 57/100\n",
      "70043/70043 [==============================] - 4s 56us/step - loss: 0.1259 - categorical_accuracy: 0.9572 - val_loss: 0.1151 - val_categorical_accuracy: 0.9640\n",
      "Epoch 58/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1249 - categorical_accuracy: 0.9577 - val_loss: 0.1129 - val_categorical_accuracy: 0.9657\n",
      "Epoch 59/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1283 - categorical_accuracy: 0.9564 - val_loss: 0.1172 - val_categorical_accuracy: 0.9631\n",
      "Epoch 60/100\n",
      "70043/70043 [==============================] - 4s 56us/step - loss: 0.1296 - categorical_accuracy: 0.9560 - val_loss: 0.1203 - val_categorical_accuracy: 0.9640\n",
      "Epoch 61/100\n",
      "70043/70043 [==============================] - 4s 56us/step - loss: 0.1274 - categorical_accuracy: 0.9559 - val_loss: 0.1255 - val_categorical_accuracy: 0.9575\n",
      "Epoch 62/100\n",
      "70043/70043 [==============================] - 4s 59us/step - loss: 0.1273 - categorical_accuracy: 0.9567 - val_loss: 0.1066 - val_categorical_accuracy: 0.9682\n",
      "Epoch 63/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1221 - categorical_accuracy: 0.9584 - val_loss: 0.1152 - val_categorical_accuracy: 0.9631\n",
      "Epoch 64/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1252 - categorical_accuracy: 0.9570 - val_loss: 0.1123 - val_categorical_accuracy: 0.9627\n",
      "Epoch 65/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1213 - categorical_accuracy: 0.9586 - val_loss: 0.1060 - val_categorical_accuracy: 0.9688\n",
      "Epoch 66/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1198 - categorical_accuracy: 0.9594 - val_loss: 0.1095 - val_categorical_accuracy: 0.9668\n",
      "Epoch 67/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1266 - categorical_accuracy: 0.9578 - val_loss: 0.1196 - val_categorical_accuracy: 0.9617\n",
      "Epoch 68/100\n",
      "70043/70043 [==============================] - 4s 63us/step - loss: 0.1293 - categorical_accuracy: 0.9564 - val_loss: 0.1137 - val_categorical_accuracy: 0.9648\n",
      "Epoch 69/100\n",
      "70043/70043 [==============================] - 5s 70us/step - loss: 0.1226 - categorical_accuracy: 0.9592 - val_loss: 0.1369 - val_categorical_accuracy: 0.9571\n",
      "Epoch 70/100\n",
      "70043/70043 [==============================] - 5s 68us/step - loss: 0.1357 - categorical_accuracy: 0.9545 - val_loss: 0.1157 - val_categorical_accuracy: 0.9653\n",
      "Epoch 71/100\n",
      "70043/70043 [==============================] - 4s 63us/step - loss: 0.1335 - categorical_accuracy: 0.9556 - val_loss: 0.1206 - val_categorical_accuracy: 0.9647\n",
      "Epoch 72/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1347 - categorical_accuracy: 0.9565 - val_loss: 0.1169 - val_categorical_accuracy: 0.9628\n",
      "Epoch 73/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1252 - categorical_accuracy: 0.9594 - val_loss: 0.1136 - val_categorical_accuracy: 0.9656\n",
      "Epoch 74/100\n",
      "70043/70043 [==============================] - 5s 68us/step - loss: 0.1238 - categorical_accuracy: 0.9588 - val_loss: 0.1102 - val_categorical_accuracy: 0.9660\n",
      "Epoch 75/100\n",
      "70043/70043 [==============================] - 5s 68us/step - loss: 0.1259 - categorical_accuracy: 0.9583 - val_loss: 0.1120 - val_categorical_accuracy: 0.9662\n",
      "Epoch 76/100\n",
      "70043/70043 [==============================] - 5s 76us/step - loss: 0.1227 - categorical_accuracy: 0.9589 - val_loss: 0.1389 - val_categorical_accuracy: 0.9535\n",
      "Epoch 77/100\n",
      "70043/70043 [==============================] - 5s 76us/step - loss: 0.1366 - categorical_accuracy: 0.9535 - val_loss: 0.1160 - val_categorical_accuracy: 0.9638\n",
      "Epoch 78/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1257 - categorical_accuracy: 0.9580 - val_loss: 0.1143 - val_categorical_accuracy: 0.9635\n",
      "Epoch 79/100\n",
      "70043/70043 [==============================] - 5s 65us/step - loss: 0.1213 - categorical_accuracy: 0.9603 - val_loss: 0.1117 - val_categorical_accuracy: 0.9669\n",
      "Epoch 80/100\n",
      "70043/70043 [==============================] - 5s 69us/step - loss: 0.1273 - categorical_accuracy: 0.9587 - val_loss: 0.1133 - val_categorical_accuracy: 0.9654\n",
      "Epoch 81/100\n",
      "70043/70043 [==============================] - 4s 63us/step - loss: 0.1175 - categorical_accuracy: 0.9614 - val_loss: 0.1113 - val_categorical_accuracy: 0.9671\n",
      "Epoch 82/100\n",
      "70043/70043 [==============================] - 5s 67us/step - loss: 0.1157 - categorical_accuracy: 0.9626 - val_loss: 0.1107 - val_categorical_accuracy: 0.9676\n",
      "Epoch 83/100\n",
      "70043/70043 [==============================] - 4s 59us/step - loss: 0.1162 - categorical_accuracy: 0.9625 - val_loss: 0.1097 - val_categorical_accuracy: 0.9683\n",
      "Epoch 84/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1135 - categorical_accuracy: 0.9631 - val_loss: 0.1066 - val_categorical_accuracy: 0.9677\n",
      "Epoch 85/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1167 - categorical_accuracy: 0.9622 - val_loss: 0.1133 - val_categorical_accuracy: 0.9648\n",
      "Epoch 86/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1160 - categorical_accuracy: 0.9613 - val_loss: 0.1076 - val_categorical_accuracy: 0.9676\n",
      "Epoch 87/100\n",
      "70043/70043 [==============================] - 4s 59us/step - loss: 0.1132 - categorical_accuracy: 0.9627 - val_loss: 0.1102 - val_categorical_accuracy: 0.9675\n",
      "Epoch 88/100\n",
      "70043/70043 [==============================] - 4s 64us/step - loss: 0.1114 - categorical_accuracy: 0.9636 - val_loss: 0.1067 - val_categorical_accuracy: 0.9696\n",
      "Epoch 89/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1123 - categorical_accuracy: 0.9631 - val_loss: 0.1107 - val_categorical_accuracy: 0.9676\n",
      "Epoch 90/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1126 - categorical_accuracy: 0.9629 - val_loss: 0.1061 - val_categorical_accuracy: 0.9685\n",
      "Epoch 91/100\n",
      "70043/70043 [==============================] - 4s 62us/step - loss: 0.1180 - categorical_accuracy: 0.9613 - val_loss: 0.1091 - val_categorical_accuracy: 0.9663\n",
      "Epoch 92/100\n",
      "70043/70043 [==============================] - 4s 61us/step - loss: 0.1160 - categorical_accuracy: 0.9628 - val_loss: 0.1062 - val_categorical_accuracy: 0.9671\n",
      "Epoch 93/100\n",
      "70043/70043 [==============================] - 4s 59us/step - loss: 0.1102 - categorical_accuracy: 0.9630 - val_loss: 0.1083 - val_categorical_accuracy: 0.9685\n",
      "Epoch 94/100\n",
      "70043/70043 [==============================] - 4s 58us/step - loss: 0.1123 - categorical_accuracy: 0.9635 - val_loss: 0.1058 - val_categorical_accuracy: 0.9687\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70043/70043 [==============================] - 5s 67us/step - loss: 0.1091 - categorical_accuracy: 0.9642 - val_loss: 0.1069 - val_categorical_accuracy: 0.9680\n",
      "Epoch 96/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1103 - categorical_accuracy: 0.9638 - val_loss: 0.1044 - val_categorical_accuracy: 0.9694\n",
      "Epoch 97/100\n",
      "70043/70043 [==============================] - 4s 56us/step - loss: 0.1071 - categorical_accuracy: 0.9646 - val_loss: 0.1054 - val_categorical_accuracy: 0.9686\n",
      "Epoch 98/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1074 - categorical_accuracy: 0.9644 - val_loss: 0.0987 - val_categorical_accuracy: 0.9702\n",
      "Epoch 99/100\n",
      "70043/70043 [==============================] - 4s 60us/step - loss: 0.1072 - categorical_accuracy: 0.9644 - val_loss: 0.1061 - val_categorical_accuracy: 0.9679\n",
      "Epoch 100/100\n",
      "70043/70043 [==============================] - 4s 57us/step - loss: 0.1066 - categorical_accuracy: 0.9645 - val_loss: 0.1062 - val_categorical_accuracy: 0.9685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bd0d493dc8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer=keras.optimizers.Adam(lr=0.1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])\n",
    "model.fit(Xtrain, Ytrain, epochs=100, batch_size=1000, validation_data=(Xval,Yval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict_classes(Xtest)\n",
    "tres=model.predict_classes(Xtrain)\n",
    "pred=tf.keras.utils.to_categorical(res,num_classes=2)\n",
    "tpred=tf.keras.utils.to_categorical(tres,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer learning\n",
    "ptb_data1=pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "ptb_data2=pd.read_csv(\"ptbdb_normal.csv\", header=None)\n",
    "ptb_1=ptb_data1.iloc[:,-1]\n",
    "ptb_2=ptb_data2.iloc[:,-1]\n",
    "Xtest_ptb=np.array(pd.concat([ptb_data1,ptb_data2]).iloc[:,:-1])\n",
    "Xtest_ptb=Xtest_ptb.reshape(Xtest_ptb.shape[0], 1, Xtest_ptb.shape[1])\n",
    "Ytest_ptb=tf.keras.utils.to_categorical(pd.concat([ptb_1,ptb_2]))\n",
    "ptb_res=model.predict_classes(Xtest_ptb)\n",
    "ptb_res=tf.keras.utils.to_categorical(ptb_res,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on train data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     57966\n",
      "           1       0.95      0.91      0.93     12077\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     70043\n",
      "   macro avg       0.97      0.95      0.96     70043\n",
      "weighted avg       0.98      0.98      0.98     70043\n",
      " samples avg       0.98      0.98      0.98     70043\n",
      "\n",
      "Stats on test data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     18118\n",
      "           1       0.94      0.88      0.91      3774\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     21892\n",
      "   macro avg       0.96      0.93      0.94     21892\n",
      "weighted avg       0.97      0.97      0.97     21892\n",
      " samples avg       0.97      0.97      0.97     21892\n",
      "\n",
      "Stats on PTB test data with transfer learning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.99      0.47      4046\n",
      "           1       0.97      0.16      0.27     10506\n",
      "\n",
      "   micro avg       0.39      0.39      0.39     14552\n",
      "   macro avg       0.64      0.57      0.37     14552\n",
      "weighted avg       0.79      0.39      0.33     14552\n",
      " samples avg       0.39      0.39      0.39     14552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats on train data:\\n\",classification_report(Ytrain,tpred))\n",
    "print(\"Stats on test data:\\n\",classification_report(Ytest,pred))\n",
    "\n",
    "print(\"Stats on PTB test data with transfer learning:\\n\",classification_report(Ytest_ptb,ptb_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
